{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Using Youtube API\n",
    "\n",
    "Building a model to get and request data from Youtube API in order to create dataset for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import nessesary libraries\n",
    "import pandas as pd\n",
    "# Google API\n",
    "# %pip install google-api-python-client # Use this command to directly install the package from Jupyter Notebook\n",
    "from googleapiclient.discovery import build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the API key\n",
    "api_key = '...' # Enter your API key here\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "#Define Keywords\n",
    "keywords = ['tự học lập trình', 'Vpop', 'chương trình giải trí', 'Vlog ăn uống', 'Vlog học','thể thao','trending','lịch sử']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get nessesary data from Youtube API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search videos to get Channel ID\n",
    "channel_ID_list = []\n",
    "def get_channel_id(keyword):\n",
    "    next_page_token = None\n",
    "    total_results = 0\n",
    "    while total_results <= 200:\n",
    "        request = youtube.search().list(\n",
    "            part='snippet',\n",
    "            q=keyword,\n",
    "            type='video',\n",
    "            maxResults=50,\n",
    "            order='relevance',\n",
    "            regionCode='VN',\n",
    "            pageToken=next_page_token\n",
    "        )\n",
    "        response = request.execute()\n",
    "        for item in response['items']:\n",
    "            channel_ID = item['snippet']['channelId']\n",
    "            if channel_ID not in channel_ID_list:\n",
    "                channel_ID_list.append(channel_ID)                \n",
    "        total_results += len(response['items'])\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        if not next_page_token:\n",
    "            break\n",
    "for keyword in keywords:\n",
    "    get_channel_id(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get data for channel_dataset\n",
    "channel_dataset = []\n",
    "channel_playlistID = []\n",
    "def get_channel_data(channel_ID):\n",
    "    request = youtube.channels().list(\n",
    "        part='snippet,statistics,contentDetails',\n",
    "        id=channel_ID\n",
    "    )\n",
    "    response = request.execute()\n",
    "    \n",
    "    for item in response['items']:\n",
    "        if int(item['statistics']['subscriberCount']) >= 300:\n",
    "            channel_data = {\n",
    "                'channel_ID': item['id'],\n",
    "                'channel_title': item['snippet']['title'],\n",
    "                'channel_description': item['snippet']['description'],\n",
    "                'channel_subscriberCount': item['statistics']['subscriberCount'],\n",
    "                'channel_viewCount': item['statistics']['viewCount'],\n",
    "                'channel_videoCount': item['statistics']['videoCount'],\n",
    "            }\n",
    "            playlist_id = item['contentDetails']['relatedPlaylists']['uploads']\n",
    "            channel_dataset.append(channel_data)\n",
    "            channel_playlistID.append(playlist_id)\n",
    "for channel_ID in channel_ID_list:\n",
    "    get_channel_data(channel_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 770 entries, 0 to 769\n",
      "Data columns (total 6 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   channel_ID               770 non-null    object\n",
      " 1   channel_title            770 non-null    object\n",
      " 2   channel_description      770 non-null    object\n",
      " 3   channel_subscriberCount  770 non-null    object\n",
      " 4   channel_viewCount        770 non-null    object\n",
      " 5   channel_videoCount       770 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 36.2+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 770 entries, 0 to 769\n",
      "Data columns (total 6 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   channel_ID               770 non-null    object\n",
      " 1   channel_title            770 non-null    object\n",
      " 2   channel_description      770 non-null    object\n",
      " 3   channel_subscriberCount  770 non-null    int64 \n",
      " 4   channel_viewCount        770 non-null    int64 \n",
      " 5   channel_videoCount       770 non-null    int64 \n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 36.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(channel_dataset)\n",
    "df.info()\n",
    "numeric_cols = ['channel_viewCount', 'channel_subscriberCount', 'channel_videoCount']\n",
    "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors = 'coerce' )\n",
    "df.info()\n",
    "df.to_csv('channel_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dataset = []\n",
    "\n",
    "def get_video_data(playlist_ID):\n",
    "    request = youtube.playlistItems().list(\n",
    "        part='snippet,contentDetails',\n",
    "        playlistId=playlist_ID,\n",
    "        maxResults=10,\n",
    "    )\n",
    "    response = request.execute()\n",
    "    \n",
    "    video_ids = [item['contentDetails']['videoId'] for item in response['items']]\n",
    "    if video_ids:\n",
    "        video_request = youtube.videos().list(\n",
    "            part='snippet,statistics,contentDetails',\n",
    "            id=','.join(video_ids),\n",
    "        )\n",
    "        video_response = video_request.execute()\n",
    "        \n",
    "        for item in video_response['items']:\n",
    "            video_data = {\n",
    "                'channel_ID': item['snippet']['channelId'],\n",
    "                'channel_title': item['snippet']['channelTitle'],\n",
    "                'video_ID': item['id'],\n",
    "                'video_title': item['snippet']['title'],                \n",
    "                'video_description': item['snippet']['description'],\n",
    "                'video_tags': item['snippet'].get('tags', None),\n",
    "                \"video_category\": item.get('brandingSettings', {}).get('video', {}).get('keywords', ''),\n",
    "                'video_viewCount': item['statistics']['viewCount'],\n",
    "                'video_likeCount': item['statistics'].get('likeCount', 0),\n",
    "                'video_commentCount': item['statistics'].get('commentCount', 0),\n",
    "                'video_dateModified': item['snippet']['publishedAt'],\n",
    "                'video_duration': item['contentDetails'].get('duration', None)\n",
    "            }\n",
    "            video_dataset.append(video_data)\n",
    "\n",
    "for playlist_id in channel_playlistID:\n",
    "    get_video_data(playlist_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thumbnails added successfully!\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('video_dataset.csv')\n",
    "\n",
    "# Hàm lấy thumbnail từ YouTube API\n",
    "def get_video_thumbnail(video_id):\n",
    "    try:\n",
    "        # Gọi API để lấy thông tin video\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet\",\n",
    "            id=video_id\n",
    "        )\n",
    "        response = request.execute()\n",
    "        \n",
    "        # Kiểm tra nếu video có tồn tại và lấy thumbnail\n",
    "        if \"items\" in response and len(response[\"items\"]) > 0:\n",
    "            thumbnails = response[\"items\"][0][\"snippet\"][\"thumbnails\"]\n",
    "            # Lấy thumbnail có độ phân giải cao nhất (maxres nếu có)\n",
    "            if 'maxres' in thumbnails:\n",
    "                return thumbnails['maxres']['url']\n",
    "            elif 'high' in thumbnails:\n",
    "                return thumbnails['high']['url']\n",
    "            elif 'medium' in thumbnails:\n",
    "                return thumbnails['medium']['url']\n",
    "            elif 'default' in thumbnails:\n",
    "                return thumbnails['default']['url']\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching thumbnail for {video_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Hàm bổ sung thumbnail vào DataFrame\n",
    "def add_thumbnails_to_dataset(df):\n",
    "    # Tạo một cột mới 'video_thumbnail' để lưu thumbnail\n",
    "    df['video_thumbnail'] = df['video_ID'].apply(get_video_thumbnail)\n",
    "    return df\n",
    "\n",
    "df_with_thumbnails = add_thumbnails_to_dataset(df)\n",
    "\n",
    "df_with_thumbnails.to_csv('video_dataset.csv', index=False)\n",
    "\n",
    "print(\"Thumbnails added successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7628 entries, 0 to 7627\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   channel_ID          7628 non-null   object\n",
      " 1   channel_title       7628 non-null   object\n",
      " 2   video_ID            7628 non-null   object\n",
      " 3   video_title         7628 non-null   object\n",
      " 4   video_description   7628 non-null   object\n",
      " 5   video_tags          4295 non-null   object\n",
      " 6   video_category      7628 non-null   object\n",
      " 7   video_viewCount     7628 non-null   object\n",
      " 8   video_likeCount     7628 non-null   object\n",
      " 9   video_commentCount  7628 non-null   object\n",
      " 10  video_dateModified  7628 non-null   object\n",
      " 11  video_duration      7603 non-null   object\n",
      "dtypes: object(12)\n",
      "memory usage: 715.3+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7628 entries, 0 to 7627\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count  Dtype              \n",
      "---  ------              --------------  -----              \n",
      " 0   channel_ID          7628 non-null   object             \n",
      " 1   channel_title       7628 non-null   object             \n",
      " 2   video_ID            7628 non-null   object             \n",
      " 3   video_title         7628 non-null   object             \n",
      " 4   video_description   7628 non-null   object             \n",
      " 5   video_tags          4295 non-null   object             \n",
      " 6   video_category      7628 non-null   object             \n",
      " 7   video_viewCount     7628 non-null   int64              \n",
      " 8   video_likeCount     7628 non-null   int64              \n",
      " 9   video_commentCount  7628 non-null   int64              \n",
      " 10  video_dateModified  7628 non-null   datetime64[ns, UTC]\n",
      " 11  video_duration      7603 non-null   object             \n",
      "dtypes: datetime64[ns, UTC](1), int64(3), object(8)\n",
      "memory usage: 715.3+ KB\n"
     ]
    }
   ],
   "source": [
    "import isodate\n",
    "\n",
    "df = pd.DataFrame(video_dataset)\n",
    "df.info()\n",
    "numeric_cols = ['video_viewCount', 'video_likeCount', 'video_commentCount']\n",
    "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors = 'coerce' )\n",
    "df['video_dateModified'] = pd.to_datetime(df['video_dateModified'], errors='coerce')\n",
    "df['video_duration'] = df['video_duration'].apply(lambda x: f\"{int(isodate.parse_duration(x).total_seconds() // 3600)}:{int((isodate.parse_duration(x).total_seconds() % 3600) // 60):02d}:{int(isodate.parse_duration(x).total_seconds() % 60):02d}\" if pd.notnull(x) else None)\n",
    "df.info()\n",
    "df.to_csv('video_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 keywords:\n",
      "shorts        0.030722\n",
      "học           0.024522\n",
      "trending      0.023875\n",
      "vlog          0.021364\n",
      "tin           0.016807\n",
      "dance         0.015098\n",
      "việt          0.013931\n",
      "tiktok        0.013535\n",
      "study         0.012738\n",
      "anh           0.012494\n",
      "funny         0.012002\n",
      "nam           0.011979\n",
      "trình         0.011344\n",
      "ăn            0.010852\n",
      "2024          0.010727\n",
      "của           0.010142\n",
      "lập           0.010006\n",
      "nhất          0.009779\n",
      "nhạc          0.009729\n",
      "ngày          0.009415\n",
      "phim          0.009174\n",
      "sử            0.009066\n",
      "video         0.008634\n",
      "làm           0.008563\n",
      "mình          0.008435\n",
      "lịch          0.008422\n",
      "sinh          0.008289\n",
      "viral         0.008094\n",
      "bóng          0.008083\n",
      "tập           0.007731\n",
      "song          0.007655\n",
      "quốc          0.007585\n",
      "mới           0.007582\n",
      "viralvideo    0.007362\n",
      "người         0.007327\n",
      "đi            0.007273\n",
      "tức           0.007153\n",
      "những         0.007131\n",
      "đá            0.007100\n",
      "có            0.006970\n",
      "kpop          0.006896\n",
      "và            0.006858\n",
      "sự            0.006790\n",
      "du            0.006678\n",
      "hà            0.006619\n",
      "comedy        0.006479\n",
      "tiếng         0.006422\n",
      "trong         0.006353\n",
      "cho           0.006332\n",
      "cùng          0.006282\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "# Bước 1: Xử lý giá trị null trong cột 'tags'\n",
    "# Thay thế các giá trị null bằng chuỗi rỗng\n",
    "df['video_tags'] = df['video_tags'].fillna('')\n",
    "\n",
    "# Bước 2: Kết hợp 'title' và 'tags' để tạo thành một cột mới cho phân tích\n",
    "df['text'] = df['video_title'] + ' ' + df['video_tags'].apply(lambda tags: ' '.join(tags) if isinstance(tags, list) else tags)\n",
    "\n",
    "# Bước 3: Tiền xử lý văn bản\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Chuyển văn bản thành chữ thường\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])  # Loại bỏ dấu câu\n",
    "    text = ' '.join([word for word in text.split() if word not in ENGLISH_STOP_WORDS])  # Loại bỏ stopwords\n",
    "    return text\n",
    "\n",
    "# Áp dụng tiền xử lý cho cột 'text'\n",
    "df['processed_text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# Bước 4: Áp dụng TfidfVectorizer để tính toán TF-IDF\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_df=0.85,             # Loại bỏ từ xuất hiện trong quá nhiều tài liệu\n",
    "    min_df=5,                # Loại bỏ từ chỉ xuất hiện trong ít tài liệu\n",
    "    max_features=5000        # Giới hạn số lượng từ khóa\n",
    ")\n",
    "\n",
    "# Tính toán ma trận TF-IDF\n",
    "tfidf_matrix = vectorizer.fit_transform(df['processed_text'])\n",
    "\n",
    "# Bước 5: Lấy tên các từ khóa từ TF-IDF\n",
    "tfidf_feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Bước 6: Tạo DataFrame từ ma trận TF-IDF\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_feature_names)\n",
    "\n",
    "# Bước 8: Hiển thị các từ khóa có trọng số cao nhất\n",
    "top_keywords = tfidf_df.mean(axis=0).sort_values(ascending=False).head(50)\n",
    "print(\"Top 50 keywords:\")\n",
    "print(top_keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "def remove_emojis(text):\n",
    "    return emoji.replace_emoji(text, replace='')\n",
    "\n",
    "def assign_category(row):\n",
    "    # Chuyển tất cả các giá trị trong video_tags và video_title thành chữ thường và loại bỏ emoji\n",
    "    tags = ' '.join(row['video_tags']).lower() if isinstance(row['video_tags'], list) else row['video_tags'].lower()\n",
    "    tags = remove_emojis(tags)\n",
    "    title = remove_emojis(row['video_title'].lower())\n",
    "    \n",
    "    # Kiểm tra từ khóa trong cột video_tags hoặc video_title\n",
    "    if any(keyword in tags or keyword in title for keyword in ['học', 'sử', 'study', 'du', 'lập', 'trình', 'code']):\n",
    "        return 'Education'\n",
    "    \n",
    "    elif any(keyword in tags or keyword in title for keyword in ['trending', 'vlog', 'tiktok', 'short', 'funny', 'viral', '2024', 'viral video']):\n",
    "        return 'Trending'\n",
    "    \n",
    "    elif any(keyword in tags or keyword in title for keyword in ['dance', 'funny', 'phim', 'kpop', 'comedy', 'nhạc']):\n",
    "        return 'Entertainment'\n",
    "    \n",
    "    elif any(keyword in tags or keyword in title for keyword in ['tập', 'bóng']):\n",
    "        return 'Fitness'\n",
    "    \n",
    "    elif 'ăn' in tags or 'ăn' in title:\n",
    "        return 'Food'\n",
    "    \n",
    "    return 'Others'\n",
    "# Áp dụng hàm vào DataFrame để tạo cột 'category'\n",
    "df['category'] = df.apply(assign_category, axis=1)\n",
    "video_dataset = df.to_dict('records')\n",
    "df.to_csv('video_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df = pd.DataFrame(video_dataset)\n",
    "# Drop the specified columns\n",
    "video_df = video_df.drop(columns=['video_category', 'text', 'processed_text'])\n",
    "video_dataset = video_df.to_dict('records')\n",
    "video_df.to_csv('video_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7628 entries, 0 to 7627\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype              \n",
      "---  ------              --------------  -----              \n",
      " 0   channel_ID          7628 non-null   object             \n",
      " 1   channel_title       7628 non-null   object             \n",
      " 2   video_ID            7628 non-null   object             \n",
      " 3   video_title         7628 non-null   object             \n",
      " 4   video_description   7628 non-null   object             \n",
      " 5   video_tags          7628 non-null   object             \n",
      " 6   video_viewCount     7628 non-null   int64              \n",
      " 7   video_likeCount     7628 non-null   int64              \n",
      " 8   video_commentCount  7628 non-null   int64              \n",
      " 9   video_dateModified  7628 non-null   datetime64[ns, UTC]\n",
      " 10  video_duration      7603 non-null   object             \n",
      " 11  category            7628 non-null   object             \n",
      " 12  like_view_ratio     7591 non-null   float64            \n",
      " 13  comment_view_ratio  7580 non-null   float64            \n",
      "dtypes: datetime64[ns, UTC](1), float64(2), int64(3), object(8)\n",
      "memory usage: 834.4+ KB\n"
     ]
    }
   ],
   "source": [
    "video_df['like_view_ratio'] = video_df['video_likeCount'] / video_df['video_viewCount']\n",
    "video_df['comment_view_ratio'] = video_df['video_commentCount'] / video_df['video_viewCount']\n",
    "video_df.info()\n",
    "video_df.to_csv('video_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df = pd.DataFrame(video_dataset)\n",
    "video_df = video_df[video_df['video_commentCount'] >= 10]\n",
    "video_dataset = video_df.to_dict('records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.errors import HttpError\n",
    "comment_dataset = []\n",
    "def get_comment_data(video_ID):\n",
    "    request = youtube.commentThreads().list(\n",
    "        part='snippet',\n",
    "        videoId=video_ID,\n",
    "        maxResults=10,\n",
    "        textFormat='plainText',\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        response = request.execute()\n",
    "        for item in response.get('items', []):\n",
    "            comment_data = {\n",
    "                'video_ID': video_ID,\n",
    "                'comment_ID': item['id'],\n",
    "                'comment_author': item['snippet']['topLevelComment']['snippet'].get('authorDisplayName', 'Unknown'),\n",
    "                'comment_text': item['snippet']['topLevelComment']['snippet']['textDisplay'],\n",
    "                'comment_date': item['snippet']['topLevelComment']['snippet']['publishedAt'],\n",
    "                'comment_likeCount': item['snippet']['topLevelComment']['snippet']['likeCount'],\n",
    "            }\n",
    "            comment_dataset.append(comment_data)\n",
    "\n",
    "    except HttpError as e:\n",
    "        print(f\"Error fetching comments for video {video_ID}: {e}\")\n",
    "\n",
    "for video in video_dataset:\n",
    "    get_comment_data(video['video_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35038 entries, 0 to 35037\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   video_ID           35038 non-null  object\n",
      " 1   comment_ID         35038 non-null  object\n",
      " 2   comment_author     35038 non-null  object\n",
      " 3   comment_text       35038 non-null  object\n",
      " 4   comment_date       35038 non-null  object\n",
      " 5   comment_likeCount  35038 non-null  int64 \n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 1.6+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35038 entries, 0 to 35037\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype              \n",
      "---  ------             --------------  -----              \n",
      " 0   video_ID           35038 non-null  object             \n",
      " 1   comment_ID         35038 non-null  object             \n",
      " 2   comment_author     35038 non-null  object             \n",
      " 3   comment_text       35038 non-null  object             \n",
      " 4   comment_date       35038 non-null  datetime64[ns, UTC]\n",
      " 5   comment_likeCount  35038 non-null  int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(1), object(4)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "comment_df = pd.DataFrame(comment_dataset)\n",
    "comment_df.info()\n",
    "comment_df['comment_date'] = pd.to_datetime(comment_df['comment_date'], errors='coerce')\n",
    "comment_df.info()\n",
    "comment_df.to_csv('comment_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "def get_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    return analysis.sentiment.polarity\n",
    "comment_data = pd.read_csv('comment_dataset.csv')\n",
    "comment_data['comment_text'] = comment_data['comment_text'].fillna('')\n",
    "comment_data['sentiment_score'] = comment_data['comment_text'].apply(get_sentiment)\n",
    "comment_data.to_csv('comment_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
